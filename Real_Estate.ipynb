{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üè† Mohammed Real Estate Demand Prediction (Professional Edition)\n",
        "\n",
        "**Author:** Mohammed Nasrallah ‚Äî Data Scientist / ML Engineer  \n",
        "**Email:** [mohammednasrallah82@gmail.com](mailto:mohammednasrallah82@gmail.com)\n",
        "\n",
        "---\n",
        "\n",
        "## üíº Project Summary\n",
        "End-to-end pipeline for **real estate demand forecasting** based on monthly transaction data across city sectors.  \n",
        "Includes **data merging**, **feature engineering**, and **LightGBM regression modeling** to predict  \n",
        "future housing transaction amounts and extract key feature importance insights.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Tech Stack\n",
        "`Python`, `Pandas`, `NumPy`, `Scikit-Learn`, `LightGBM`, `Matplotlib`, `Seaborn`\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Repro Steps\n",
        "1Ô∏è‚É£ Place all raw CSVs (`land_transactions`, `new_house_transactions`, `pre_owned_house_transactions`, etc.) under `/content`  \n",
        "2Ô∏è‚É£ Run all notebook cells sequentially (top to bottom)  \n",
        "3Ô∏è‚É£ Outputs: model metrics (MAE, RMSE, MAPE) and final prediction file ‚Üí **submission_mohammed_final.csv**\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Performance Summary\n",
        "| Metric | Score |\n",
        "|:-------|------:|\n",
        "| **MAE**  | 1623.041 |\n",
        "| **RMSE** | 4647.608 |\n",
        "| **MAPE** | 0.214 |\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Notes\n",
        "- Code is **fully commented** and designed for clarity & reproducibility.  \n",
        "- Built for **interview-readiness** and **portfolio showcasing**.  \n",
        "- Can be easily adapted to other cities or real-estate datasets.\n"
      ],
      "metadata": {
        "id": "9E_dl_BDtGkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üèóÔ∏è Stage 1: Setup & Data Loading\n",
        "# ------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
        "\n",
        "BASE_PATH = \"/content\"\n",
        "\n",
        "# Load all CSV files\n",
        "files = {\n",
        "    \"city_indexes\": pd.read_csv(f\"{BASE_PATH}/city_indexes.csv\"),\n",
        "    \"city_search_index\": pd.read_csv(f\"{BASE_PATH}/city_search_index.csv\"),\n",
        "    \"land_transactions\": pd.read_csv(f\"{BASE_PATH}/land_transactions.csv\"),\n",
        "    \"land_transactions_nearby\": pd.read_csv(f\"{BASE_PATH}/land_transactions_nearby_sectors.csv\"),\n",
        "    \"new_house\": pd.read_csv(f\"{BASE_PATH}/new_house_transactions.csv\"),\n",
        "    \"new_house_nearby\": pd.read_csv(f\"{BASE_PATH}/new_house_transactions_nearby_sectors.csv\"),\n",
        "    \"pre_owned\": pd.read_csv(f\"{BASE_PATH}/pre_owned_house_transactions.csv\"),\n",
        "    \"pre_owned_nearby\": pd.read_csv(f\"{BASE_PATH}/pre_owned_house_transactions_nearby_sectors.csv\"),\n",
        "    \"sector_poi\": pd.read_csv(f\"{BASE_PATH}/sector_POI.csv\"),\n",
        "    \"test\": pd.read_csv(f\"{BASE_PATH}/test.csv\"),\n",
        "    \"sample_submission\": pd.read_csv(f\"{BASE_PATH}/sample_submission.csv\")\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Data loaded successfully.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# üßπ Stage 2: Cleaning & Standardization\n",
        "# ------------------------------------------------------------\n",
        "for name, df in files.items():\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "    files[name] = df\n",
        "\n",
        "for key in [\n",
        "    \"land_transactions\", \"land_transactions_nearby\",\n",
        "    \"new_house\", \"new_house_nearby\",\n",
        "    \"pre_owned\", \"pre_owned_nearby\",\n",
        "    \"city_search_index\"\n",
        "]:\n",
        "    if \"month\" in files[key].columns:\n",
        "        files[key][\"month\"] = pd.to_datetime(\n",
        "            files[key][\"month\"].str.replace(\"_\", \"-\").str.replace(\" \", \"-\"),\n",
        "            errors=\"coerce\", format=\"%Y-%b\"\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ Columns standardized and dates parsed.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# üß© Stage 3: Merging All Datasets\n",
        "# ------------------------------------------------------------\n",
        "merged_df = files[\"new_house\"].copy()\n",
        "merge_list = [\n",
        "    \"land_transactions\",\n",
        "    \"land_transactions_nearby\",\n",
        "    \"pre_owned\",\n",
        "    \"pre_owned_nearby\",\n",
        "    \"new_house_nearby\",\n",
        "    \"sector_poi\"\n",
        "]\n",
        "\n",
        "for name in merge_list:\n",
        "    df = files[name].copy()\n",
        "    common_cols = [c for c in [\"month\", \"sector\"] if c in df.columns]\n",
        "    merged_df = pd.merge(merged_df, df, on=common_cols, how=\"left\")\n",
        "    print(f\"üîó Merged with {name:<30} ‚Üí shape: {merged_df.shape}\")\n",
        "\n",
        "print(\"‚úÖ All files merged successfully.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# üß† Stage 4: Feature Engineering\n",
        "# ------------------------------------------------------------\n",
        "df = merged_df.copy()\n",
        "df = df[~df[\"amount_new_house_transactions\"].isna()].copy()\n",
        "\n",
        "# Handle missing values\n",
        "for col in df.columns:\n",
        "    if df[col].dtype in [\"float64\", \"int64\"]:\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "    else:\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "# Time features\n",
        "df[\"month\"] = pd.to_datetime(df[\"month\"], errors=\"coerce\")\n",
        "df[\"year\"] = df[\"month\"].dt.year\n",
        "df[\"month_num\"] = df[\"month\"].dt.month\n",
        "df[\"ym_idx\"] = (df[\"year\"] - df[\"year\"].min()) * 12 + df[\"month_num\"]\n",
        "\n",
        "# Label encode sector\n",
        "le = LabelEncoder()\n",
        "df[\"sector\"] = le.fit_transform(df[\"sector\"].astype(str))\n",
        "\n",
        "print(\"‚úÖ Feature engineering complete.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# ‚öôÔ∏è Stage 5: Model Training (LightGBM)\n",
        "# ------------------------------------------------------------\n",
        "cat_cols = [\"sector\"]\n",
        "num_cols = [c for c in df.columns if c not in [\"month\", \"amount_new_house_transactions\", \"sector\"]\n",
        "            and pd.api.types.is_numeric_dtype(df[c])]\n",
        "\n",
        "X_all = df[cat_cols + num_cols].fillna(0)\n",
        "y_all = df[\"amount_new_house_transactions\"].astype(float)\n",
        "\n",
        "# Split (time-based)\n",
        "cut_ym = np.quantile(df[\"ym_idx\"], 0.80)\n",
        "train_idx = df[\"ym_idx\"] <= cut_ym\n",
        "val_idx = df[\"ym_idx\"] > cut_ym\n",
        "\n",
        "X_train, y_train = X_all.loc[train_idx], y_all.loc[train_idx]\n",
        "X_val, y_val = X_all.loc[val_idx], y_all.loc[val_idx]\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}\")\n",
        "\n",
        "# Train LightGBM model\n",
        "model = lgb.LGBMRegressor(\n",
        "    objective=\"regression\",\n",
        "    boosting_type=\"gbdt\",\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    max_depth=-1,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    bagging_freq=5,\n",
        "    random_state=42,\n",
        "    n_estimators=1000\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          eval_set=[(X_val, y_val)],\n",
        "          eval_metric=\"mae\",\n",
        "          callbacks=[lgb.early_stopping(100), lgb.log_evaluation(100)])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# üìä Stage 6: Evaluation\n",
        "# ------------------------------------------------------------\n",
        "def mape(y_true, y_pred, eps=1e-9):\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    return np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), eps, None)))\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "mape_val = mape(y_val, y_pred)\n",
        "\n",
        "print(\"\\nüìà Model Evaluation Results:\")\n",
        "print(f\"MAE   : {mae:.3f}\")\n",
        "print(f\"RMSE  : {rmse:.3f}\")\n",
        "print(f\"MAPE  : {mape_val:.3f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# üèÅ Stage 7: Submission File Generation\n",
        "# ------------------------------------------------------------\n",
        "test_df = pd.read_csv(f\"{BASE_PATH}/test.csv\")\n",
        "test_df[\"month\"] = test_df[\"id\"].apply(lambda x: \"-\".join(x.split(\"_\")[:2]))\n",
        "test_df[\"sector\"] = test_df[\"id\"].apply(lambda x: x.split(\"_\")[-1])\n",
        "test_df[\"month\"] = pd.to_datetime(test_df[\"month\"], errors=\"coerce\")\n",
        "\n",
        "test_merged = test_df.copy()\n",
        "merge_files = [\n",
        "    \"land_transactions\", \"land_transactions_nearby\",\n",
        "    \"new_house\", \"new_house_nearby\",\n",
        "    \"pre_owned\", \"pre_owned_nearby\", \"sector_poi\"\n",
        "]\n",
        "\n",
        "for name in merge_files:\n",
        "    temp = files[name]\n",
        "    if \"month\" in temp.columns and \"sector\" in temp.columns:\n",
        "        test_merged = pd.merge(test_merged, temp, on=[\"month\", \"sector\"], how=\"left\")\n",
        "    elif \"sector\" in temp.columns:\n",
        "        test_merged = pd.merge(test_merged, temp, on=\"sector\", how=\"left\")\n",
        "\n",
        "test_merged = test_merged.fillna(0)\n",
        "test_merged[\"sector\"] = le.transform([s if s in le.classes_ else le.classes_[0] for s in test_merged[\"sector\"].astype(str)])\n",
        "\n",
        "common_cols = [c for c in (cat_cols + num_cols) if c in test_merged.columns]\n",
        "missing_cols = [c for c in (cat_cols + num_cols) if c not in test_merged.columns]\n",
        "for c in missing_cols:\n",
        "    test_merged[c] = 0\n",
        "\n",
        "X_test = test_merged[cat_cols + num_cols]\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "submission = pd.read_csv(f\"{BASE_PATH}/sample_submission.csv\")\n",
        "submission[\"new_house_transaction_amount\"] = preds\n",
        "submission.to_csv(\"/content/submission_mohammed_final.csv\", index=False)\n",
        "\n",
        "print(\"\\n‚úÖ Submission file created successfully! ‚Üí submission_mohammed_final.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZphdqkftIr3",
        "outputId": "92cfe48d-d4aa-429d-a80d-d457378be605"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data loaded successfully.\n",
            "‚úÖ Columns standardized and dates parsed.\n",
            "üîó Merged with land_transactions              ‚Üí shape: (5433, 15)\n",
            "üîó Merged with land_transactions_nearby       ‚Üí shape: (5433, 19)\n",
            "üîó Merged with pre_owned                      ‚Üí shape: (5433, 23)\n",
            "üîó Merged with pre_owned_nearby               ‚Üí shape: (5433, 27)\n",
            "üîó Merged with new_house_nearby               ‚Üí shape: (5433, 36)\n",
            "üîó Merged with sector_poi                     ‚Üí shape: (5433, 177)\n",
            "‚úÖ All files merged successfully.\n",
            "‚úÖ Feature engineering complete.\n",
            "Train: (4355, 178), Validation: (1078, 178)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1141490714.py:85: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "/tmp/ipython-input-1141490714.py:83: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's l1: 1661.14\tvalid_0's l2: 2.06569e+07\n",
            "Early stopping, best iteration is:\n",
            "[93]\tvalid_0's l1: 1623.04\tvalid_0's l2: 2.16003e+07\n",
            "\n",
            "üìà Model Evaluation Results:\n",
            "MAE   : 1623.041\n",
            "RMSE  : 4647.608\n",
            "MAPE  : 0.214\n",
            "\n",
            "‚úÖ Submission file created successfully! ‚Üí submission_mohammed_final.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1141490714.py:162: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  test_df[\"month\"] = pd.to_datetime(test_df[\"month\"], errors=\"coerce\")\n",
            "/tmp/ipython-input-1141490714.py:178: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  test_merged = test_merged.fillna(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFLICqbPtVIL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}